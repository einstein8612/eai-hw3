# environment
task: fish-swim
modality: 'state'
action_repeat: 4
discount: 0.99
episode_length: 250
train_steps: 200_000 # this is often enough to get good results


device: cuda

# algorithm
use_real_model: false
policy: 'mpc' # mpc or random
mpc_algo: "random"
use_td: false


obs_shape: ???
action_shape: ???
action_dim: ???
obs_dim: ???

# planning
iterations: 6
num_samples: 512
num_elites: 64
mixture_coef: 0.05
min_std: 0.05
temperature: 0.5
momentum: 0.1

# learning
batch_size: 512
max_buffer_size: 1_000_000
horizon: 5
reward_coef: 0.5
value_coef: 0.1
dynamics_coef: 2
rho: 0.5
kappa: 0.1
lr: 1e-3
std_schedule: linear(0.5, ${min_std}, 25000)
horizon_schedule: linear(1, ${horizon}, 25000)
per_alpha: 0.6
per_beta: 0.4
grad_clip_norm: 10
seed_steps: 5000
update_freq: 2
tau: 0.01

# architecture
enc_dim: 256
mlp_dim: 512
d_ensemble: 1
q_ensemble: 2

# misc
seed: 715
exp_name: default
eval_freq: 20000
eval_episodes: 5
save_model: true
save_freq: 20
load_model: false
load_path: ''
eval_only: false